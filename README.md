# Background

From the original : https://keras.io/examples/nlp/lstm_seq2seq/#characterlevel-recurrent-sequencetosequence-model by François Chollet

*"This example demonstrates how to implement a basic character-level recurrent sequence-to-sequence model. We apply it to translating short English sentences into short French sentences, character-by-character. Note that it is fairly unusual to do character-level machine translation, as word-level models are more common in this domain.""

The original author of the RNN architecture defined in build method of the Trainer class (inside train.py) is François Chollet. See Keras examples : https://keras.io/examples/nlp/lstm_seq2seq/#characterlevel-recurrent-sequencetosequence-model . 

The extra bits added here are :

 - wrapping classes : *Trainer , Predictor* and *Preprocessor*
 - scripts for operability
 - A persistence method for trained model and predicted outputs.

## Setup Instructions

The following instructions assume you have downloaded the git repository , e.g. by doing: 

git clone https://github.com/asierabreu/sequencer

1. Create a python virtual environment :python3 -m venv virtualenv
2. Activate this environment : source virtualenv/bin/activate
3. Install dependencies : pip3 install -r requirements.txt
4. (Optional) Install kernel for virtual env: ipython kernel install --name "virtualenv" --user

## Folder structure

 - training_files : contains the input for the trainign process
 - predict_input : contains the input for the predict process
 - predict_input : contains the output of the predict process
 - scripts : contains Python executables
 - models : contains output models saved during training
 - config.txt : is the overal config file

## Configuration

The following configuration parameters are editable under the config.txt file:

 - train_dir=./training_files
 - model_dir=./models
 - predict_in=./predict_input
 - predict_out=./predict_output
 - latent_dim=256
 - num_samples=10000
 - optimizer=rmsprop
 - loss=categorical_crossentropy
 - metrics=accuracy
 - batch_size=64
 - epochs=100
 - val_split=0.2

## Usage 

 - Model training : python scripts/train.py
 - Model prediction : python scripts/predict.py